---
title: "Get started with washr"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Get started with washr}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE
)
```

```{r setup}
library(washr)
library(devtools)
```

We show the workflow of `washr` to develop an openwashdata data package with a toy dataset `fssample`. The `fssample` data is a (imaginary) 5-day sample collection of faecal sludge.

> You are taking 20 samples of 1 liter faecal sludge from pit latrines and septic tanks at households and public toilets (5 samples each). For each sample, you note the number of daily users of the sanitation system.[^1]

[^1]: Your sample collection starts on 1st November 2022. On day 5, you analyse the data in the laboratory for totals solids (TS) in g/L. In your spreadsheet, note the exact date of each collected sample.

    This is you data collection plan:

    - Day 1: 5 samples at households using pit latrines 
    - Day 2: 5 samples at households using septic tanks 
    - Day 3: 5 samples at public toilets that are pit latrines 
    - Day 4: 5 samples at public toilets that are septic tanks 
    - Day 5: Analyses of all 20 samples for total solids (TS) in g/L on a lab scale with accuracy of 0.01 g 
    
    Make up the results for the total solids (TS) analyses (e.g. 12.48 g/L).

# 1. Create and process dataset

Once you initialize an R package named with `fssample` with `devtools`, we can start to set up the raw data in the package by executing:

```{r setup_rawdata}
setup_rawdata()
```

Under the `fssample` directory, there is now a new directory `data-raw` with an R script `data-processing.R` inside it. Go to `data-processing.R` and refer to our template code to import, clean, and export the dataset. For instance, you may want to change the data type of the column "location" to be factor or reformat the column "date" into `YYYY-MM-DD`.

After executing the last a few lines in `data-processing.R`, namely,

```{r export_data}
usethis::use_data(fssample, overwrite = TRUE)
fs::dir_create(here::here("inst", "extdata"))
readr::write_csv(fssample,
                 here::here("inst", "extdata", paste0("fssample", ".csv")))
openxlsx::write.xlsx(fssample,
                     here::here("inst", "extdata", paste0("fssample", ".xlsx")))
```

A directory `data/` that contains tidy datasets should now exist under the `fssample` directory.

# 2. Document dataset

Now that we have the tidy data ready, we want to make sure that the dataset has good documentation for re-use and re-producibility. This includes to document the package itself as well as the datasets.

For documenting the package, we work with the DESCRIPTION file by running:

```{r update_dict}
update_description()
```

Now we focus on the dataset documentation. We first create a dictionary for the dataset in the CSV format.

```{r}
setup_dictionary()
```

Go to `data-raw/dictionary.csv`, open it, and fill in the empty column `description` of the dictionary. Once the dictionary is complete, we document the dataset into an R documentation by executing:

```{r}
setup_roxygen()
```

Go to `R/` and fill in the title and description for the dataset.

# Communicate dataset

Now we have both the R dataset and its documentation ready. It's time to communicate with the public using more human-readable and visually appealing tools. We currently achieve this with the following two components.

-   README
-   pkgdown website

```{r}
setup_readme()
# Go to README.Rmd and complete this R Markdown file
build_readme() # Generate README.md from README.Rmd
setup_website()
```

Now, it's time to work on polishing the README and website. Once you are satisfied with them, don't forget to re-run `build_readme()` and `build_site()` again to update.
